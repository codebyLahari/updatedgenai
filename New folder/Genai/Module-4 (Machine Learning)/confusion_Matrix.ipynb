{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " **Business Problem**\n",
        " \"How can a company automatically classify incoming emails as spam or legitimate (ham) to ensure a cleaner, more productive inbox for its employees and reduce security risks?\""
      ],
      "metadata": {
        "id": "WBU4E-0mtFkn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here are the required libraies\n",
        "\n",
        "**pandas** for reading dataset to dataframs\n",
        "\n",
        "**CountVectorizer** tokenizes the input text. Tokenization is the process of breaking down the text into individual words (or tokens).\n",
        "\n",
        "**Logistic Regression** can be used to classify emails as either \"spam\" or \"not spam\" based on features extracted from the email content.\n",
        "\n",
        "**train_test_split**  is a utility function in scikit-learn that splits your dataset into two subsets: a training set and a testing set.\n",
        "\n",
        "**confusion_matrix** It helps to visualize the performance of a classification model by comparing the predicted classifications to the actual true values.\n",
        "\n",
        "**matplotlib** used for interactive visualizations.\n"
      ],
      "metadata": {
        "id": "SZbabbofuDMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay,classification_report, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ahmedhassansaqr/email-spam-detection-v2\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "data_file = None\n",
        "for file in os.listdir(path):\n",
        "    # Check for common data file extensions\n",
        "    if file.endswith((\".csv\", \".tsv\", \".txt\", \".data\")):\n",
        "        data_file = os.path.join(path, file)\n",
        "        break\n",
        "\n",
        "if data_file is None:\n",
        "    print(\"No supported data file found in the dataset folder.\")\n",
        "else:\n",
        "    print(f\"Found data file: {data_file}\")\n",
        "    # Try different delimiters based on common data file formats\n",
        "    try:\n",
        "        df = pd.read_csv(data_file, sep=',')  # Try comma delimiter first\n",
        "    except pd.errors.ParserError:\n",
        "        try:\n",
        "            df = pd.read_csv(data_file, sep='\\t')  # Try tab delimiter\n",
        "        except pd.errors.ParserError:\n",
        "            try:\n",
        "                df = pd.read_csv(data_file, delim_whitespace=True)  # Try space delimiter\n",
        "            except pd.errors.ParserError:\n",
        "                print(\"Unable to determine the correct delimiter for the data file.\")\n",
        "                df = None\n",
        "\n",
        "    if df is not None:\n",
        "        print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA4u_528t2ng",
        "outputId": "c4a9adb1-a558-444d-db47-c62f121f73a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/ahmedhassansaqr/email-spam-detection-v2/versions/1\n",
            "Found data file: /root/.cache/kagglehub/datasets/ahmedhassansaqr/email-spam-detection-v2/versions/1/smsspamcollection.tsv\n",
            "  label                                            message  length  punct\n",
            "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
            "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
            "3   ham  U dun say so early hor... U c already then say...      49      6\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Preprocessing\n",
        "X = df['label']  # Feature: email content\n",
        "y = df['message']  # Target: spam or not (0 or 1)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Train-test split (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Text vectorization (Bag-of-Words)\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4NMXmU5lhNY",
        "outputId": "16655938-6c2d-40dd-b994-f9c5dee4c5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                            message  length  punct\n",
            "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
            "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
            "3   ham  U dun say so early hor... U c already then say...      49      6\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform cross-validation with the logistic regression model\n",
        "cv_scores = cross_val_score(model, X_train_vect, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation scores: {cv_scores}\")\n",
        "print(f\"Mean accuracy: {cv_scores.mean()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5kx_AA6x8Ob",
        "outputId": "a7e5b5f7-ff74-474e-fbf9-89b8af55e35d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.0044843  0.00560538 0.00448934 0.00448934 0.00448934]\n",
            "Mean accuracy: 0.004711539913333636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Set up the hyperparameter grid\n",
        "param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Set up GridSearchCV to find the best hyperparameter\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_vect, y_train)\n",
        "\n",
        "# Print best hyperparameter and score\n",
        "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation accuracy: {grid_search.best_score_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0sAfjMYyGY_",
        "outputId": "018456f6-a8f2-40e3-cd23-59ab20880baa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 100}\n",
            "Best cross-validation accuracy: 0.004936006804467193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Initialize and train the Multinomial Naive Bayes model\n",
        "model_nb = MultinomialNB()\n",
        "model_nb.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_nb = model_nb.predict(X_test_vect)"
      ],
      "metadata": {
        "id": "5DBvm_XryRqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# Evaluate performance\n",
        "cm_nb = confusion_matrix(y_test, y_pred_nb)\n",
        "print(\"Confusion Matrix (Naive Bayes):\")\n",
        "print(cm_nb)\n",
        "\n",
        "#print(\"\\nClassification Report (Naive Bayes):\")\n",
        "#print(classification_report(y_test, y_pred_nb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpFqwKV9v3n4",
        "outputId": "1cd99d28-62a0-4001-ebec-1cc2c90d71d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Naive Bayes):\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    }
  ]
}